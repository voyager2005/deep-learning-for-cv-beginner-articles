{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/voyager2005/deep-learning-for-cv-beginner-articles/blob/main/notebooks/MNIST_Digit_Recognition_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction**\n",
        "\n",
        "Welcome to our tutorial on digit classification using the MNIST dataset. In our article we have already explained the reason for choosing MNIST for today’s project. Its images being grey scale and small size helps us play around and even write our own digits on and see how well our model works **(we do this in the last section of the colab)**\n"
      ],
      "metadata": {
        "id": "A6mQ8NoylgWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setup and Installation [don’t skip]**\n",
        "\n",
        "In this section we are just going to verify if all of the necessary libraries are installed. Google colab typically comes preinstalled with these libraries but well double check everything just to ensure you have an error free journey.Additionally, we'll verify if a GPU is available, as it can significantly speed up our model's training process.\n",
        "\n",
        "**IMPORTANT:** *You can enable a GPU by going to **Runtime > Change runtime type** and selecting **GPU**.* We advise using the T4 GPU, this is a free GPU available for all Google Colab users and works well.\n",
        "\n",
        "If you are executing this for the first time it can take anywhere between 30s to 1m\n"
      ],
      "metadata": {
        "id": "s1I8rtlkW4-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading and Exploring the MNIST Dataset**\n",
        "\n",
        "In this section, we will load the dataset using TensorFlow and vialize a few samples to understand its structure\n",
        "The general strcuture of this is in the form of (x, y, z) where\n",
        "- x: the number of images available\n",
        "- y: the height of the image\n",
        "- z: the width of the image\n",
        "\n",
        "Inside the code you will also see a variable named images_count, you can change the value set for this image to see examples of images that are available in the data set along with their lables (lables are a fancy way of saying \"correct answer\")\n",
        "\n",
        "**IMPORTANT:** keep the value of images_count between 1 and 9, we have made this just to ensure that a large number does not break Google Colab\n",
        "\n",
        "The Explaination of this code is given below it to get an indepth understanding on what is happening in the code!!"
      ],
      "metadata": {
        "id": "P0lHo6OiXt9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Checking the TensorFlow version\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Checking if a GPU is available\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"GPU is available and ready to use!\")\n",
        "else:\n",
        "    print(\"No GPU available. Using CPU instead.\")"
      ],
      "metadata": {
        "id": "M7AxHmbCXsJT",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the MNIST dataset from TensorFlow/Keras\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Displaying the shape of the training and test sets\n",
        "print(f\"Training set shape: {x_train.shape}, Labels shape: {y_train.shape}\")\n",
        "print(f\"Test set shape: {x_test.shape}, Labels shape: {y_test.shape}\")\n",
        "\n",
        "# Visualizing a few images from the training set\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# please change this value depending upon the number of samples you want to see\n",
        "images_count = 9\n",
        "\n",
        "for i in range(images_count):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(x_train[i], cmap='gray')\n",
        "    plt.title(f\"Label: {y_train[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "E2gf7ySFXtd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Code Explanation**\n",
        "\n",
        "1. **Loading the Dataset**: We use `tf.keras.datasets.mnist.load_data()` to load the dataset, which returns the training and test images along with their labels.\n",
        "\n",
        "2. **Displaying the Shape**: The code prints out the dimensions of the images and labels, showing how many examples are available in each set.\n",
        "\n",
        "3. **Visualizing Images**: We use `matplotlib` to display a 3x3 grid of images from the training set with their corresponding labels, giving users a visual sense of the dataset.\n"
      ],
      "metadata": {
        "id": "JYKsmbiVYTiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing the Data**\n",
        "\n",
        "Before training our model, we need to preprocess the MNIST dataset. This involves normalizing\\* the pixel values and reshaping\\* the data to make it compatible with our neural network.\n",
        "\n",
        "- **Normalization**: The images currently have pixel values ranging from 0 to 255. We will scale these values to the range 0-1 for faster convergence during training.\n",
        "- **Reshaping**: The images are in 2D (28x28), but neural networks typically expect an additional channel dimension. We'll reshape the images to add this channel.\n",
        "\n",
        "Dont worry if this all seems complex, over time you will get an understanding for these and it will seem easier than ever!"
      ],
      "metadata": {
        "id": "AMCrtcKMYiqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing the pixel values\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Reshaping the images to add a single channel (28, 28) -> (28, 28, 1)\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# One-hot encoding the labels (optional step)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Displaying the updated shapes\n",
        "print(f\"Training set shape after preprocessing: {x_train.shape}, Labels shape: {y_train.shape}\")\n",
        "print(f\"Test set shape after preprocessing: {x_test.shape}, Labels shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "id": "LkLf_vs0YiJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building the Neural Network Model**\n",
        "\n",
        "Now that our data is preprocessed, it’s time to build our neural network model. We will use TensorFlow's Keras API to define a simple feedforward neural network for digit classification.\n",
        "\n",
        "The architecture will consist of:\n",
        "- An input layer to receive the image data.\n",
        "- One or more hidden layers to learn the features.\n",
        "- An output layer that will classify the images into one of the 10 digit classes (0-9).\n",
        "\n",
        "Let’s define our model and add the necessary layers.\n",
        "\n",
        "**There is an explaination for the code below with all the terms and words that are new to us**"
      ],
      "metadata": {
        "id": "JtvbYWzmZifN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the neural network model\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Input layer (flattening the input data)\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28, 1)))\n",
        "\n",
        "# Hidden layer (first hidden layer with 128 neurons and ReLU activation)\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "\n",
        "# Output layer (10 neurons for 10 classes with softmax activation)\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Displaying the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "InoTIzPVZqYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Explanation\n",
        "\n",
        "1. **Input Layer**: The `Flatten` layer transforms the 28x28 input images into a 1D array of 784 pixels, making it suitable for the dense layers.\n",
        "\n",
        "2. **Hidden Layer**: The first `Dense` layer has 128 neurons and uses the ReLU (Rectified Linear Unit) activation function, allowing the model to learn complex features from the data.\n",
        "\n",
        "3. **Output Layer**: The final `Dense` layer has 10 neurons (one for each digit) and uses the softmax activation function, which outputs probabilities for each class.\n",
        "\n",
        "4. **Model Summary**: The `model.summary()` function provides a detailed overview of the model architecture, including the number of parameters.\n"
      ],
      "metadata": {
        "id": "-s6MNzkiZyB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding Model Compilation\n",
        "\n",
        "Just like any other programming language, before running the program, the program needs to be compiled. Here before we can train the model we need to prepare it for training. This step is called model compilation.We have already covered what model compilation is, things like loss functions and optimizers in our article.\n",
        "\n",
        "Without compilation, our model would not know how to learn from the data. It needs these loss functions, optimzers and mertices to improve and track its progress.\n"
      ],
      "metadata": {
        "id": "PY1StcxHZ5a3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "ZdBiccRbZ6j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Model\n",
        "\n",
        "Now that our model is compiled, it's time to train the model. By definition, \"Training is the process where the model leans from the data\". Let’s break down this definition and understand what happens during model training.\n",
        "\n",
        "1. **Training:**\n",
        "\n",
        "    The process where we teach our model to recognize patters is called training, here we are just teaching our model to recognize handwritten digits.\n",
        "\n",
        "2. **How does training work?**\n",
        "\n",
        "    While training our model we divide our image dataset into two categories the training set and the testing set as you can see in the image below.\n",
        "    ![Train Test Split](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/4_train-test-split.jpg)\n",
        "    We use the training set along with the loss function and optimizer to train the model to get better at digit recognition.\n",
        "\n",
        "3. **EPOCH**\n",
        "\n",
        "    We divide the training set into several batches, in our example its 10. We do so to make the learning process efficient. One full pass through of the entire training dataset (each batch for us is 1500) is called an epoch. The model might not learn in a single epoch so we use multiple epochs to give it more chances to learn.\n",
        "\n",
        "4. **fit**\n",
        "\n",
        "    We use the `fit` function to train the model. This function takes the training data, the labels (correct answers), the number of epochs, and the batch size (how many images to process at a time).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mOEKpz75aCfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluating the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "HT_FQqv2aG1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing Training History"
      ],
      "metadata": {
        "id": "g2usyc5qaLD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing training history\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plotting training and validation accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting training and validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wBjgp47BaPTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OUR OWN HANDWRITING!!!**\n",
        "\n",
        "Now that our model is all trained we can see how well our model works!!! Welcome to the final part of this colab, the hand written digit detection!! In this section you will be able to draw a digit on your computer, upload that and see how well our neural network works."
      ],
      "metadata": {
        "id": "TaFIbEAt-oLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How It Works\n",
        "\n",
        "### Generate and Download a Blank Canvas\n",
        "I have provided a 28x28 pixel black canvas for you to draw in the code below. This is the size of every image on MNIST and is the ideal canvas to run our tests on.\n",
        "\n",
        "To get started, follow these steps:\n",
        "\n",
        "1. **Download the black canvas**: A button will be provided to download the blank canvas image (a `.png` file).\n",
        "2. **Draw your digit**: Open the downloaded image in any image editor (such as Paint, GIMP, Photoshop, etc.), and use a white brush to draw a digit (0-9) on the black background.\n",
        "    - Make sure your drawing stays within the 28x28 pixel canvas.\n",
        "    - White color represents the digit, and the black background should be left untouched.\n",
        "3. **Save the image** after drawing your digit.\n",
        "\n",
        "## Tips for Drawing Digits\n",
        "\n",
        "- Make sure the digit is clearly visible and takes up most of the canvas.\n",
        "- Keep the background black and the digit white to match the MNIST dataset format.\n",
        "- If the digit is too small or unclear, the model might have difficulty recognizing it.\n",
        "\n",
        "I hope you enjoy experimenting with your custom canvas, if you have any issues in understanding how this works, here below is a video of me running this on my laptop so you can just follow along and keep having fun"
      ],
      "metadata": {
        "id": "SRbxbTKq5FSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files\n",
        "\n",
        "# Create a black 28x28 image (same format as MNIST)\n",
        "black_canvas = np.zeros((28, 28), dtype=np.uint8)\n",
        "\n",
        "# Save the black canvas image to disk\n",
        "cv2.imwrite('/content/black_digit_image.png', black_canvas)\n",
        "\n",
        "# Display the black canvas in the notebook\n",
        "cv2_imshow(black_canvas)\n",
        "\n",
        "# Download button for the image\n",
        "def download_canvas():\n",
        "    files.download('/content/black_digit_image.png')\n",
        "\n",
        "# Create a button to download the black canvas\n",
        "import ipywidgets as widgets\n",
        "download_button = widgets.Button(description=\"Download Black Canvas\")\n",
        "download_button.on_click(lambda x: download_canvas())\n",
        "display(download_button)\n"
      ],
      "metadata": {
        "id": "V6x81Giapgqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload Your Custom Digit Image\n",
        "Once you've drawn your digit on the canvas:\n",
        "\n",
        "1. Run the code\n",
        "2. Click the **Choose Files** provided in the notebook.\n",
        "3. Select the image with your custom handwritten digit that you just saved."
      ],
      "metadata": {
        "id": "9rzT3CIWwD9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import cv2\n",
        "\n",
        "# Upload custom handwritten digit image\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load and preprocess the uploaded image\n",
        "for fn in uploaded.keys():\n",
        "    # Load image\n",
        "    img = cv2.imread(fn, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (28, 28))  # Resize to 28x28\n",
        "    img = img / 255.0  # Normalize the image\n",
        "    img = img.reshape(1, 28, 28, 1)  # Reshape to (1, 28, 28, 1)\n",
        "\n",
        "    # Predict the class (digit)\n",
        "    prediction = np.argmax(model.predict(img), axis=-1)\n",
        "    print(f'Predicted digit: {prediction[0]}')"
      ],
      "metadata": {
        "id": "x-IpikXqm7tN",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Limitations\n",
        "\n",
        "Even though our model does a good job recognizing handwritten digits, there are a few things it struggles with:\n",
        "\n",
        "1. **It Only Knows What It’s Seen**: Our model has been trained only with MNIST images, which are simple, clean, and black-and-white. If you show it something different, like colorful or messy digits, it might get confused. It’s like learning to read with only one type of handwriting—seeing a different style can throw you off!\n",
        "\n",
        "2. **Too Focused on the Practice Test**: Sometimes, our model does really well on the training data but doesn’t do as great when faced with new, real-world examples. It's like studying hard for one test but struggling when the questions change even a little.\n",
        "\n",
        "3. **Limited Skillset**: This model is a \"digit expert\"—it's really only trained for numbers. So, if you ask it to recognize anything other than digits, it won’t know what to do. Imagine trying to use a calculator for writing an essay; it just doesn't fit the job!\n",
        "\n",
        "4. **Takes a Lot of Brainpower**: Running and training models like this can be demanding for computers, making it slower on devices with less power. Think of it like trying to play a video game on an old phone—it’s not as smooth or fast.\n",
        "\n",
        "5. **It Can Be Unfair**: The dataset we used is based on specific writing styles. So, if someone writes differently or in a script the model isn’t familiar with, it might not work well. It’s like not understanding someone because they have a different accent.\n",
        "\n"
      ],
      "metadata": {
        "id": "jRlpGgnsaakl"
      }
    }
  ]
}